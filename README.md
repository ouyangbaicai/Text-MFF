# Text-MFF (Expert Systems With Applications, 2026)：
  
#### 欢迎参考和引用我们的工作(Welcome to refer to and cite our work)  
#### 文章发表在Expert Systems with Applications Volume 262, 1 March 2025上
#### Code for paper [“FusionGCN: Multi-focus image fusion using superpixel features generation GCN and pixel-level feature reconstruction CNN”](https://www.sciencedirect.com/science/article/pii/S0957417424025326).  
  
# Acknowledgments ※  
训练、测试框架由 [MFFT(EAAI, 2024)](https://www.sciencedirect.com/science/article/abs/pii/S0952197624001258) 构建而来。  
网络结构由 [ArtFlow(CVPR, 2021)](https://openaccess.thecvf.com/content/CVPR2021/html/An_ArtFlow_Unbiased_Image_Style_Transfer_via_Reversible_Neural_Flows_CVPR_2021_paper.html) 和 [Text-IF(CVPR, 2024)](https://openaccess.thecvf.com/content/CVPR2024/html/Yi_Text-IF_Leveraging_Semantic_Text_Guidance_for_Degradation-Aware_and_Interactive_Image_CVPR_2024_paper.html) 启发而来。  
感谢上述所有作者的杰出工作。 
  
The training and testing framework is built by [MFFT(EAAI, 2024)](https://www.sciencedirect.com/science/article/abs/pii/S0952197624001258).  
The network structure is inspired by [ArtFlow(CVPR, 2021)](https://openaccess.thecvf.com/content/CVPR2021/html/An_ArtFlow_Unbiased_Image_Style_Transfer_via_Reversible_Neural_Flows_CVPR_2021_paper.html) and [Text-IF(CVPR, 2024)](https://openaccess.thecvf.com/content/CVPR2024/html/Yi_Text-IF_Leveraging_Semantic_Text_Guidance_for_Degradation-Aware_and_Interactive_Image_CVPR_2024_paper.html).  
Thank you to all the authors mentioned above for their outstanding work.  
  
# Disadvantages and future optimization directions  
-   The generation of statements is limited by a fixed vocabulary.
-   Only cosine similarity may mislead the network into producing incorrect statements.
-   Unable to effectively address strong and variable degradation interference.
  
# How to use ※
-   仅提供关键代码和权重。
-   Only provide key codes and weights.  
-   完整代码构建可参考FusionGCN项目。  
-   The complete code construction can refer to the FusionGCN project.
-   仅需简单替换即可完成。
-   Simply replace it to complete.

# submitted and accepted dates (25-26)  
-   **Fitst Sbumit:** STJ(6.17)→WE(6.18)→UR(7.5)→DIP(9.15)→**Revise**  
-   **R1:** STJ(9.18)→WE(9.18)→UR(9.24)→DIP(10.6)→**Revise**  
-   **R2:** STJ(10.8)→WE(10.8)→UR(10.16)→DIP(12.24)→**Revise**  
-   **R3:** STJ(12.26)→WE(1.7)→UR(1.11)→DIP(1.14)→**Revise**
-   **R4:** STJ(1.19)→WE(1.19)→UR(1.22)→DIP(1.26)→**Acepted**

# Reference information ※  
```  
@article{Ouyang2025FusionGCN,
  title={FusionGCN: Multi-focus image fusion using superpixel features generation GCN and pixel-level feature reconstruction CNN},  
  author={Yuncan Ouyang and Hao Zhai and Hanyue Hu and Xiaohang Li and Zhi Zeng},  
  journal={Expert Systems with Applications},  
  pages={125665},  
  year={2025},  
  publisher={Elsevier}  
}
```
  
### Or  
  
```
Ouyang Y, Zhai H, Hu H, et al. FusionGCN: Multi-focus image fusion using superpixel features generation GCN and pixel-level feature reconstruction CNN[J]. Expert Systems with Applications, 2025: 125665.
```

# Contact information  
E-mail addresses: 2023210516060@stu.cqnu.edu.cn (Y. Ouyang)
